{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EeZ0O3eS7U7n"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "Z0fKAVx97XTS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8Y-b3RS7-Cr",
        "outputId": "d95c7978-8bdf-4994-bb04-d03b567afbc1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "-nzFpdJx7eOQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Текст для обробки\n",
        "text_2 = \"This is an example sentence for tokenization and lemmatization.\"\n",
        "text = \"\"\"He was standing in the middle of the Great Hall, but the four house tables were gone. Instead, there were\n",
        "more than a hundred smaller tables, all facing the same way, at each of which sat a student, head bent\n",
        "low, scribbling on a roll of parchment. The only sound was the scratching of quills and the occasional rustle\n",
        "as someone adjusted their parchment. It was clearly exam time.\n",
        "Sunshine was streaming through the high windows on to the bent heads, which shone chestnut and copper\n",
        "and gold in the bright light. Harry looked around carefully. Snape had to be here somewhere … this was his\n",
        "memory …\n",
        "And there he was, at a table right behind Harry. Harry stared. Snape-the-teenager had a stringy, pallid look\n",
        "about him, like a plant kept in the dark. His hair was lank and greasy and was flopping on to the table, his\n",
        "hooked nose barely half an inch from the surface of the parchment as he scribbled. Harry moved around\n",
        "behind Snape and read the heading of the examination paper: DEFENCE AGAINST THE DARK ARTS –\n",
        "ORDINARY WIZARDING LEVEL.\n",
        "So Snape had to be fifteen or sixteen, around Harry’s own age. His hand was flying across the parchment;\n",
        "he had written at least a foot more than his closest neighbours, and yet his writing was minuscule and\n",
        "cramped.\n",
        "“Five more minutes!”\n",
        "The voice made Harry jump. Turning, he saw the top of Professor Flitwick’s head moving between the\n",
        "desks a short distance away. Professor Flitwick was walking past a boy with untidy black hair … very untidy\n",
        "black hair …\n",
        "Harry moved so quickly that, had he been solid, he would have knocked desks flying. Instead he seemed to\n",
        "slide, dreamlike, across two aisles and up a third.\"\"\"\n",
        "\n",
        "# Токенізація\n",
        "doc = nlp(text)\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfqunUHm7ijy",
        "outputId": "822e4c19-8a4d-4635-faec-544ff8a89bc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'was', 'standing', 'in', 'the', 'middle', 'of', 'the', 'Great', 'Hall', ',', 'but', 'the', 'four', 'house', 'tables', 'were', 'gone', '.', 'Instead', ',', 'there', 'were', '\\n', 'more', 'than', 'a', 'hundred', 'smaller', 'tables', ',', 'all', 'facing', 'the', 'same', 'way', ',', 'at', 'each', 'of', 'which', 'sat', 'a', 'student', ',', 'head', 'bent', '\\n', 'low', ',', 'scribbling', 'on', 'a', 'roll', 'of', 'parchment', '.', 'The', 'only', 'sound', 'was', 'the', 'scratching', 'of', 'quills', 'and', 'the', 'occasional', 'rustle', '\\n', 'as', 'someone', 'adjusted', 'their', 'parchment', '.', 'It', 'was', 'clearly', 'exam', 'time', '.', '\\n', 'Sunshine', 'was', 'streaming', 'through', 'the', 'high', 'windows', 'on', 'to', 'the', 'bent', 'heads', ',', 'which', 'shone', 'chestnut', 'and', 'copper', '\\n', 'and', 'gold', 'in', 'the', 'bright', 'light', '.', 'Harry', 'looked', 'around', 'carefully', '.', 'Snape', 'had', 'to', 'be', 'here', 'somewhere', '…', 'this', 'was', 'his', '\\n', 'memory', '…', '\\n', 'And', 'there', 'he', 'was', ',', 'at', 'a', 'table', 'right', 'behind', 'Harry', '.', 'Harry', 'stared', '.', 'Snape', '-', 'the', '-', 'teenager', 'had', 'a', 'stringy', ',', 'pallid', 'look', '\\n', 'about', 'him', ',', 'like', 'a', 'plant', 'kept', 'in', 'the', 'dark', '.', 'His', 'hair', 'was', 'lank', 'and', 'greasy', 'and', 'was', 'flopping', 'on', 'to', 'the', 'table', ',', 'his', '\\n', 'hooked', 'nose', 'barely', 'half', 'an', 'inch', 'from', 'the', 'surface', 'of', 'the', 'parchment', 'as', 'he', 'scribbled', '.', 'Harry', 'moved', 'around', '\\n', 'behind', 'Snape', 'and', 'read', 'the', 'heading', 'of', 'the', 'examination', 'paper', ':', 'DEFENCE', 'AGAINST', 'THE', 'DARK', 'ARTS', '–', '\\n', 'ORDINARY', 'WIZARDING', 'LEVEL', '.', '\\n', 'So', 'Snape', 'had', 'to', 'be', 'fifteen', 'or', 'sixteen', ',', 'around', 'Harry', '’s', 'own', 'age', '.', 'His', 'hand', 'was', 'flying', 'across', 'the', 'parchment', ';', '\\n', 'he', 'had', 'written', 'at', 'least', 'a', 'foot', 'more', 'than', 'his', 'closest', 'neighbours', ',', 'and', 'yet', 'his', 'writing', 'was', 'minuscule', 'and', '\\n', 'cramped', '.', '\\n', '“', 'Five', 'more', 'minutes', '!', '”', '\\n', 'The', 'voice', 'made', 'Harry', 'jump', '.', 'Turning', ',', 'he', 'saw', 'the', 'top', 'of', 'Professor', 'Flitwick', '’s', 'head', 'moving', 'between', 'the', '\\n', 'desks', 'a', 'short', 'distance', 'away', '.', 'Professor', 'Flitwick', 'was', 'walking', 'past', 'a', 'boy', 'with', 'untidy', 'black', 'hair', '…', 'very', 'untidy', '\\n', 'black', 'hair', '…', '\\n', 'Harry', 'moved', 'so', 'quickly', 'that', ',', 'had', 'he', 'been', 'solid', ',', 'he', 'would', 'have', 'knocked', 'desks', 'flying', '.', 'Instead', 'he', 'seemed', 'to', '\\n', 'slide', ',', 'dreamlike', ',', 'across', 'two', 'aisles', 'and', 'up', 'a', 'third', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokens = word_tokenize(text)\n",
        "sentences = sent_tokenize(text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n"
      ],
      "metadata": {
        "id": "KW6MdXsk7k9e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "punctuation = string.punctuation + '\\n'"
      ],
      "metadata": {
        "id": "fIb2d9h28IEC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stop_words:\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text not in word_frequencies.keys():\n",
        "        word_frequencies[word.text] = 1\n",
        "      else:\n",
        "        word_frequencies[word.text] += 1"
      ],
      "metadata": {
        "id": "4KIOG6ni8LvM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "1400zjwO-qQQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select_length = int(len(word_frequencies))\n",
        "summary = nlargest(select_length, word_frequencies, key = word_frequencies.get)\n"
      ],
      "metadata": {
        "id": "OtGmpouV-zhO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3ndU3Yk_1G3",
        "outputId": "1aea231f-06b7-4911-e874-1caa82496a4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Harry',\n",
              " 'parchment',\n",
              " 'Snape',\n",
              " '…',\n",
              " 'around',\n",
              " 'hair',\n",
              " 'tables',\n",
              " 'Instead',\n",
              " 'head',\n",
              " 'bent',\n",
              " 'table',\n",
              " 'behind',\n",
              " 'moved',\n",
              " '’s',\n",
              " 'flying',\n",
              " 'across',\n",
              " 'Professor',\n",
              " 'Flitwick',\n",
              " 'desks',\n",
              " 'untidy',\n",
              " 'black',\n",
              " 'standing',\n",
              " 'middle',\n",
              " 'Great',\n",
              " 'Hall',\n",
              " 'four',\n",
              " 'house',\n",
              " 'gone',\n",
              " 'hundred',\n",
              " 'smaller',\n",
              " 'facing',\n",
              " 'way',\n",
              " 'sat',\n",
              " 'student',\n",
              " 'low',\n",
              " 'scribbling',\n",
              " 'roll',\n",
              " 'sound',\n",
              " 'scratching',\n",
              " 'quills',\n",
              " 'occasional',\n",
              " 'rustle',\n",
              " 'someone',\n",
              " 'adjusted',\n",
              " 'clearly',\n",
              " 'exam',\n",
              " 'time',\n",
              " 'Sunshine',\n",
              " 'streaming',\n",
              " 'high',\n",
              " 'windows',\n",
              " 'heads',\n",
              " 'shone',\n",
              " 'chestnut',\n",
              " 'copper',\n",
              " 'gold',\n",
              " 'bright',\n",
              " 'light',\n",
              " 'looked',\n",
              " 'carefully',\n",
              " 'somewhere',\n",
              " 'memory',\n",
              " 'right',\n",
              " 'stared',\n",
              " 'teenager',\n",
              " 'stringy',\n",
              " 'pallid',\n",
              " 'look',\n",
              " 'like',\n",
              " 'plant',\n",
              " 'kept',\n",
              " 'dark',\n",
              " 'lank',\n",
              " 'greasy',\n",
              " 'flopping',\n",
              " 'hooked',\n",
              " 'nose',\n",
              " 'barely',\n",
              " 'half',\n",
              " 'inch',\n",
              " 'surface',\n",
              " 'scribbled',\n",
              " 'read',\n",
              " 'heading',\n",
              " 'examination',\n",
              " 'paper',\n",
              " 'DEFENCE',\n",
              " 'DARK',\n",
              " 'ARTS',\n",
              " '–',\n",
              " 'ORDINARY',\n",
              " 'WIZARDING',\n",
              " 'LEVEL',\n",
              " 'fifteen',\n",
              " 'sixteen',\n",
              " 'age',\n",
              " 'hand',\n",
              " 'written',\n",
              " 'least',\n",
              " 'foot',\n",
              " 'closest',\n",
              " 'neighbours',\n",
              " 'yet',\n",
              " 'writing',\n",
              " 'minuscule',\n",
              " 'cramped',\n",
              " '“',\n",
              " 'Five',\n",
              " 'minutes',\n",
              " '”',\n",
              " 'voice',\n",
              " 'made',\n",
              " 'jump',\n",
              " 'Turning',\n",
              " 'saw',\n",
              " 'top',\n",
              " 'moving',\n",
              " 'short',\n",
              " 'distance',\n",
              " 'away',\n",
              " 'walking',\n",
              " 'past',\n",
              " 'boy',\n",
              " 'quickly',\n",
              " 'solid',\n",
              " 'would',\n",
              " 'knocked',\n",
              " 'seemed',\n",
              " 'slide',\n",
              " 'dreamlike',\n",
              " 'two',\n",
              " 'aisles',\n",
              " 'third']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5rmpAxUN-eY",
        "outputId": "cd8b1b19-540c-4568-f4aa-fbffdd0a1883"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'standing': 1,\n",
              " 'middle': 1,\n",
              " 'Great': 1,\n",
              " 'Hall': 1,\n",
              " 'four': 1,\n",
              " 'house': 1,\n",
              " 'tables': 2,\n",
              " 'gone': 1,\n",
              " 'Instead': 2,\n",
              " 'hundred': 1,\n",
              " 'smaller': 1,\n",
              " 'facing': 1,\n",
              " 'way': 1,\n",
              " 'sat': 1,\n",
              " 'student': 1,\n",
              " 'head': 2,\n",
              " 'bent': 2,\n",
              " 'low': 1,\n",
              " 'scribbling': 1,\n",
              " 'roll': 1,\n",
              " 'parchment': 4,\n",
              " 'sound': 1,\n",
              " 'scratching': 1,\n",
              " 'quills': 1,\n",
              " 'occasional': 1,\n",
              " 'rustle': 1,\n",
              " 'someone': 1,\n",
              " 'adjusted': 1,\n",
              " 'clearly': 1,\n",
              " 'exam': 1,\n",
              " 'time': 1,\n",
              " 'Sunshine': 1,\n",
              " 'streaming': 1,\n",
              " 'high': 1,\n",
              " 'windows': 1,\n",
              " 'heads': 1,\n",
              " 'shone': 1,\n",
              " 'chestnut': 1,\n",
              " 'copper': 1,\n",
              " 'gold': 1,\n",
              " 'bright': 1,\n",
              " 'light': 1,\n",
              " 'Harry': 7,\n",
              " 'looked': 1,\n",
              " 'around': 3,\n",
              " 'carefully': 1,\n",
              " 'Snape': 4,\n",
              " 'somewhere': 1,\n",
              " '…': 4,\n",
              " 'memory': 1,\n",
              " 'table': 2,\n",
              " 'right': 1,\n",
              " 'behind': 2,\n",
              " 'stared': 1,\n",
              " 'teenager': 1,\n",
              " 'stringy': 1,\n",
              " 'pallid': 1,\n",
              " 'look': 1,\n",
              " 'like': 1,\n",
              " 'plant': 1,\n",
              " 'kept': 1,\n",
              " 'dark': 1,\n",
              " 'hair': 3,\n",
              " 'lank': 1,\n",
              " 'greasy': 1,\n",
              " 'flopping': 1,\n",
              " 'hooked': 1,\n",
              " 'nose': 1,\n",
              " 'barely': 1,\n",
              " 'half': 1,\n",
              " 'inch': 1,\n",
              " 'surface': 1,\n",
              " 'scribbled': 1,\n",
              " 'moved': 2,\n",
              " 'read': 1,\n",
              " 'heading': 1,\n",
              " 'examination': 1,\n",
              " 'paper': 1,\n",
              " 'DEFENCE': 1,\n",
              " 'DARK': 1,\n",
              " 'ARTS': 1,\n",
              " '–': 1,\n",
              " 'ORDINARY': 1,\n",
              " 'WIZARDING': 1,\n",
              " 'LEVEL': 1,\n",
              " 'fifteen': 1,\n",
              " 'sixteen': 1,\n",
              " '’s': 2,\n",
              " 'age': 1,\n",
              " 'hand': 1,\n",
              " 'flying': 2,\n",
              " 'across': 2,\n",
              " 'written': 1,\n",
              " 'least': 1,\n",
              " 'foot': 1,\n",
              " 'closest': 1,\n",
              " 'neighbours': 1,\n",
              " 'yet': 1,\n",
              " 'writing': 1,\n",
              " 'minuscule': 1,\n",
              " 'cramped': 1,\n",
              " '“': 1,\n",
              " 'Five': 1,\n",
              " 'minutes': 1,\n",
              " '”': 1,\n",
              " 'voice': 1,\n",
              " 'made': 1,\n",
              " 'jump': 1,\n",
              " 'Turning': 1,\n",
              " 'saw': 1,\n",
              " 'top': 1,\n",
              " 'Professor': 2,\n",
              " 'Flitwick': 2,\n",
              " 'moving': 1,\n",
              " 'desks': 2,\n",
              " 'short': 1,\n",
              " 'distance': 1,\n",
              " 'away': 1,\n",
              " 'walking': 1,\n",
              " 'past': 1,\n",
              " 'boy': 1,\n",
              " 'untidy': 2,\n",
              " 'black': 2,\n",
              " 'quickly': 1,\n",
              " 'solid': 1,\n",
              " 'would': 1,\n",
              " 'knocked': 1,\n",
              " 'seemed': 1,\n",
              " 'slide': 1,\n",
              " 'dreamlike': 1,\n",
              " 'two': 1,\n",
              " 'aisles': 1,\n",
              " 'third': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}